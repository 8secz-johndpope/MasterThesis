\chapter{Conclusion}
\par In this paper, we propose a presentation training system that allows the trainee to imitate past famous speech to improve their presentation skills. 
\par In advance, we employed OpenPose library\cite{cao2017realtime} to extract orators' motion data from past famous speech 2D video. OpenPose is a library for real-time multi-person key-point detection, which can extract 2D coordinates from 2D image or video. We select the John F.Kennedy's \emph{We choose to go to the Moon} as our target video. In this speech, he used some gestures to stress his words and used some suitable pause to make speech more impressive. We think it's a suitable speech for our proposed system.
We select eight kinds of joint as our target joints because most behaviors showed in our target speech are the behaviors of the upper half of the body. 
\par While training, the system capture the trainee's motion in real-time using a Microsoft Kinect camera (Kinect for short). The Kinect can extract 25 kinds of joint's 3D coordinates from a human body. We only employ eight kinds of joint's 2D coordinates to pair the joints which extracted by OpenPose from famous past speech. 
\par Then, we employ a template algorithm to compare the trainee's speech with the famous past speech. We choose the cosine similarity of adjacent limbs as the feature to calculate the score that shows the similarity of the trainees' motion and the motion of extracted orators.
\par Finally, the system gives the trainee visual feedback to make the training more effective. In training, the trainee wears an HMD (Oculus Rift) that shows a virtual hall and some virtual audience. The audience will perform some actions according to the score in real-time. For example, when the trainee gets a high score, the audience applauds for the trainee.

\par We made two experiments to verify the effectiveness of our algorithm and system. In the first experiment, we proved that our algorithm could compare the trainee's motion and the orator's motion of famous past speech. In the second experiment, we made an A/B test to verify will imitating past famous speech by our proposed system can improve trainee's presentation skill. The experiment result shows that the trainee performs better after training. From the interview and the recorded video, we find that imitating past famous speech let the trainee use more gestures and eye contact in their presentation. It shows the effectiveness of our proposed system.

\par In our present system, we only employ the upper body's gestures to judge the trainee's presentation. However, we also consider some other behaviors in the experiment such as whole body movement, vocal behaviors, and postural behaviors. Those behaviors are also necessary because there are many kinds of style of presentation. Some speech like inaugural speech (A speech given during this ceremony which informs the people of his or her intentions as a leader.) or congress speech needs the speaker stands behind a podium and can't move a lot. In the other recent speech style like TED or conference, the speaker moves in the stage and make more interaction with the audience. 
\par In the future, we would like to consider more behaviors such as eye contact, whole body movement and vocal behaviors in our proposed system. We also need to improve our algorithm and feedback for more effective training. 

